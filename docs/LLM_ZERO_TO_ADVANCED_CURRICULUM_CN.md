# 从 0 到 LLM 系统能力：边学边干学习手册（面向零基础）

> 适用对象：无 AI 背景、希望系统学习并可实操训练 MiniMind 的学习者。  
> 硬件假设：RTX 3050（8GB 显存级别）。

---

## 0. 先校准目标：什么叫“达到 MIT/哈佛学生水平”？

先说实话：

- **MIT/哈佛学生水平**并不是“背很多概念”，而是：
  1) 能清晰解释原理；
  2) 能复现实验；
  3) 能分析失败原因；
  4) 能做一个小型但完整的研究/工程项目。

所以我们把目标拆成 4 层：

1. **概念层**：你能讲明白 Token、Attention、Pretrain/SFT/RLHF 在干什么。
2. **实现层**：你能跑通 MiniMind 的训练链路并改关键超参。
3. **分析层**：你能读 loss 曲线、定位 OOM/不收敛/过拟合问题。
4. **项目层**：你能交付一个小领域模型（例如客服/医疗问答 demo）并写技术报告。

> 这份手册不是“速成”，而是“可落地 + 可复现 + 可持续升级”的路线。

---

## 1. 学习路线总览（36 周，9 个月）

- **阶段 A（第 1-4 周）**：编程与数学地基（Python、线代、概率、微积分最小集）
- **阶段 B（第 5-10 周）**：机器学习基础（监督学习、优化、评估）
- **阶段 C（第 11-16 周）**：深度学习核心（MLP/CNN/RNN、反向传播、正则化）
- **阶段 D（第 17-24 周）**：Transformer 与 LLM（Tokenizer、Attention、Pretrain、SFT）
- **阶段 E（第 25-30 周）**：对齐与推理增强（DPO/RLHF、评测、提示工程）
- **阶段 F（第 31-36 周）**：毕业项目（训练 + 评测 + 部署 + 报告）

每周学习配比建议：

- 理论学习：40%
- 代码实践：40%
- 复盘写作：20%

每周最低投入：8-12 小时（建议 10 小时）。

---

## 2. 每一阶段学什么、做什么（由浅入深）

## 阶段 A（第 1-4 周）：地基阶段

### 目标

- 会用 Python 写函数、类、文件读写、基础数据处理。
- 知道向量/矩阵、导数、概率分布的直觉意义。

### 必读概念

- Python：列表、字典、for 循环、函数、模块。
- 线性代数：向量点积、矩阵乘法、维度。
- 概率统计：均值、方差、条件概率、期望。
- 微积分：导数、链式法则（理解反向传播必备）。

### 小练习（必须动手）

1. 用 Python 实现均值、方差函数（不要用 numpy）。
2. 手写一个 2x2 矩阵乘法函数。
3. 用 `matplotlib` 画一条函数曲线并计算数值导数。

### 验收标准

- 你能解释“为什么梯度下降要用导数”。

---

## 阶段 B（第 5-10 周）：机器学习基础

### 目标

- 理解“模型=函数，训练=最小化损失”。
- 会使用训练/验证/测试集。

### 必读概念

- 回归、分类、交叉熵、过拟合、欠拟合。
- 梯度下降、学习率、Batch、Epoch。
- 评估指标：Accuracy / Precision / Recall / F1。

### 小练习

1. 用 `scikit-learn` 训练一个二分类模型。
2. 手动调学习率（3 组）并对比收敛曲线。
3. 写一个 1 页实验记录：参数、结果、结论。

### 验收标准

- 你能回答“为什么验证集表现好于测试集不一定可靠”。

---

## 阶段 C（第 11-16 周）：深度学习核心

### 目标

- 理解神经网络如何通过反向传播更新参数。
- 会用 PyTorch 写训练循环。

### 必读概念

- MLP、激活函数（ReLU/GELU）、归一化。
- 反向传播、自动求导、梯度裁剪。
- Dropout、Weight Decay、Early Stopping。

### 小练习

1. 用 PyTorch 手写一个 2 层 MLP 做 MNIST。
2. 比较“有/无 Dropout”的验证误差。
3. 手动打印每层梯度范数，观察是否梯度爆炸。

### 验收标准

- 你能解释“为什么 loss 降了但泛化没变好”。

---

## 阶段 D（第 17-24 周）：Transformer 与 LLM 主线

### 目标

- 掌握 LLM 核心结构与 MiniMind 训练流程。
- 能在 3050 上跑通最小训练闭环。

### 必读概念

- Tokenizer、Embedding、Self-Attention、FFN。
- 位置编码（RoPE）、上下文长度。
- Pretrain（下一词预测）与 SFT（指令跟随）的差异。

### MiniMind 对应实操（边学边干）

1. 环境安装与 CUDA 检查。
2. 跑通 `eval_llm.py` 推理。
3. 小参数跑 `train_pretrain.py`。
4. 接着跑 `train_full_sft.py`。
5. 再次用 `eval_llm.py` 对比效果。

### 推荐训练命令模板（3050 起步档）

在 `trainer/` 目录：

```bash
python train_pretrain.py --batch_size 1 --accumulation_steps 16 --max_seq_len 128 --num_workers 2 --dtype float16
python train_full_sft.py --batch_size 1 --accumulation_steps 16 --max_seq_len 128 --num_workers 2 --dtype float16 --from_weight pretrain
```

在项目根目录：

```bash
python eval_llm.py --weight full_sft
```

### 小练习

1. 只改 `max_seq_len`（128/192/256），记录显存和速度变化。
2. 只改 `accumulation_steps`（8/16/32），观察 loss 波动。
3. 写结论：哪个参数对 3050 最敏感，为什么？

### 验收标准

- 你能解释“为什么小显卡要用梯度累积”。

---

## 阶段 E（第 25-30 周）：对齐与评测能力

### 目标

- 理解 DPO / RLHF 的基本思想和适用场景。
- 能做小规模评测并形成可复现实验结论。

### 必读概念

- 偏好数据（chosen/rejected）是什么。
- DPO 与 PPO/GRPO 的差异（离线偏好 vs 在线奖励优化）。
- 评测维度：有用性、真实性、一致性、格式遵循。

### 小练习

1. 跑一个最小 DPO 训练（小数据）。
2. 设计 20 条固定问题，比较 SFT 模型与 DPO 模型输出。
3. 建立人工评分表（1-5 分），计算平均分差异。

### 验收标准

- 你能回答“为什么 DPO 提升风格但不一定提升事实性”。

---

## 阶段 F（第 31-36 周）：毕业项目（对标高校课程期末）

### 目标

交付一个完整项目（建议二选一）：

1. **领域助手模型**（如法律/医疗/电商客服）
2. **训练优化项目**（如低显存训练效率对比）

### 必交付物

1. `README`：问题定义、数据来源、方法、结果。
2. 实验表格：关键超参 + 指标 + 成本（时间/显存）。
3. 误差分析：至少 20 条失败样例。
4. 演示脚本：可运行推理 demo。

### 验收标准（“MIT/哈佛同等能力”对齐）

你达到以下 4 点，就已经接近一流课程项目要求：

- 能清晰定义问题和假设。
- 能设计对照实验并复现。
- 能解释负结果（为什么失败）。
- 能提出下一步改进方案并估计成本。

---

## 3. 每周固定学习模板（可直接照做）

- **Day 1（理论）**：看 1-2 小时概念 + 做 20 分钟笔记。
- **Day 2（代码）**：跑通 1 个最小实验。
- **Day 3（调参）**：只改 1 个参数做对照。
- **Day 4（复盘）**：写“本周学到了什么、哪里没懂”。
- **Day 5（输出）**：录 5 分钟口述，讲解本周核心原理。

> 你不是在“看懂 AI”，你是在“训练自己成为会做实验的人”。

---

## 4. 推荐的学习资产（按阶段）

### 入门数学/编程

- 3Blue1Brown（线代/微积分直觉）
- CS50 Python（编程基础）

### 机器学习/深度学习

- 吴恩达机器学习（基础直觉）
- fast.ai（偏工程实战）
- 李沐《动手学深度学习》（理论+代码兼顾）

### LLM 专项

- Transformer 原论文（先看图和结论再看公式）
- Hugging Face NLP Course
- MiniMind `README.md` + `trainer/*.py`（直接对照源码）

---

## 5. 你的“边学边干”任务清单（Checklist）

### 初级（1-3 个月）

- [ ] 能独立搭好环境并验证 CUDA
- [ ] 能跑通 pretrain + sft + eval
- [ ] 能读懂 loss 曲线并做简单调参

### 中级（4-6 个月）

- [ ] 能解释并对比 Full SFT / LoRA / DPO
- [ ] 能做 3 组以上对照实验
- [ ] 能写结构化实验报告

### 高级（7-9 个月）

- [ ] 能完成一个领域小模型项目
- [ ] 能分析失败样例并提出改进路线
- [ ] 能向别人讲清楚“为什么这样设计实验”

---

## 6. 针对 3050 的现实建议（很重要）

1. 永远先做小实验验证流程，再扩规模。
2. 显存不够优先走 LoRA，再考虑全参数微调。
3. 评测样本固定化（同一批问题），才能比较模型是否进步。
4. 每次只改一个变量，不要同时改 5 个参数。

---

## 7. 最后：如何逼近“名校水平”

你真正要对齐的不是学校名，而是**研究训练方式**：

- 提问题（Hypothesis）
- 做实验（Experiment）
- 看证据（Evidence）
- 写结论（Conclusion）
- 做迭代（Iteration）

如果你连续 9 个月按本手册执行，你会从“零基础”成长为：

- 能独立训练小模型
- 能做规范实验
- 能完成可展示项目

这就是和优秀高校学生在能力结构上最关键的共同点。
